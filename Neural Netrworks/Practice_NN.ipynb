{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFALX1K2f9H1QWzmYTwjMP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6DP5GMK7KNCu","executionInfo":{"status":"ok","timestamp":1711451419757,"user_tz":0,"elapsed":536,"user":{"displayName":"Siddharth Asthana","userId":"02587652800522319733"}},"outputId":"3cd30c12-fa64-4d5e-e2eb-e29f04734b14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 and loss: 1.1224557161331177\n","Epoch 10 and loss: 0.26079532504081726\n","Epoch 20 and loss: 0.11196835339069366\n","Epoch 30 and loss: 0.0652126744389534\n","Epoch 40 and loss: 0.045915890485048294\n","Epoch 50 and loss: 0.030438585206866264\n","Epoch 60 and loss: 0.0274417195469141\n","Epoch 70 and loss: 0.025059852749109268\n","Epoch 80 and loss: 0.023842932656407356\n","Epoch 90 and loss: 0.022803129628300667\n","1.) tensor([-3.4486,  7.8776, -7.0923]) \t 1 \t 1\n","2.) tensor([ 20.5991,  10.0827, -32.0010]) \t 0 \t 0\n","3.) tensor([ 21.0665,  10.2620, -32.6718]) \t 0 \t 0\n","4.) tensor([ 21.5690,  10.4547, -33.3928]) \t 0 \t 0\n","5.) tensor([-3.4142,  7.8415, -7.0920]) \t 1 \t 1\n","6.) tensor([-4.2982,  8.5767, -7.4055]) \t 1 \t 1\n","7.) tensor([ 21.4622,  10.4138, -33.2396]) \t 0 \t 0\n","8.) tensor([-20.4106,   1.2757,  11.1640]) \t 2 \t 2\n","9.) tensor([ 20.0085,   9.9837, -31.2776]) \t 0 \t 0\n","10.) tensor([ 22.1648,  10.6833, -34.2479]) \t 0 \t 0\n","11.) tensor([-0.7237,  8.6255, -9.6157]) \t 1 \t 1\n","12.) tensor([-3.9495,  7.5978, -6.4779]) \t 1 \t 1\n","13.) tensor([-25.6077,   0.7911,  14.8318]) \t 2 \t 2\n","14.) tensor([-26.2660,   1.2461,  14.7807]) \t 2 \t 2\n","15.) tensor([ 18.6905,  10.1443, -30.0350]) \t 0 \t 0\n","16.) tensor([-12.9965,   5.1636,   1.9896]) \t 1 \t 1\n","17.) tensor([-14.8756,   3.7859,   4.7920]) \t 2 \t 2\n","18.) tensor([-7.7179,  6.2635, -2.5885]) \t 1 \t 1\n","19.) tensor([ 25.7841,  12.0715, -39.4420]) \t 0 \t 0\n","20.) tensor([-20.8341,   1.1919,  11.5079]) \t 2 \t 2\n","21.) tensor([-16.4302,   3.3607,   6.2664]) \t 2 \t 2\n","22.) tensor([-2.7502,  8.1348, -7.8049]) \t 1 \t 1\n","23.) tensor([-17.1749,   2.5400,   7.6973]) \t 1 \t 2\n","24.) tensor([-3.5458,  8.6041, -7.8928]) \t 1 \t 1\n","25.) tensor([ 19.5834,   9.6931, -30.5433]) \t 0 \t 0\n","26.) tensor([-2.7851,  7.0633, -6.5213]) \t 1 \t 1\n","27.) tensor([ 21.6746,  10.4952, -33.5444]) \t 0 \t 0\n","28.) tensor([ 19.4100,   9.6265, -30.2944]) \t 0 \t 0\n","29.) tensor([-8.1001,  6.3090, -2.3902]) \t 1 \t 1\n","30.) tensor([-22.6569,   1.5269,  12.2856]) \t 2 \t 2\n","We got 29 correct\n"," Fuck off _|_ \t My first Neural Network is here\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (fc1): Linear(in_features=4, out_features=8, bias=True)\n","  (fc2): Linear(in_features=8, out_features=9, bias=True)\n","  (out): Linear(in_features=9, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":5}],"source":["from itertools import count\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Model(nn.Module):\n","    def __init__(self, in_features=4, H1=8, H2=9, out_features=3):\n","        super(Model, self).__init__()  # Correcting super() call indentation\n","        self.fc1 = nn.Linear(in_features, H1)  # Correcting capitalization to nn.Linear\n","        self.fc2 = nn.Linear(H1, H2)  # Correcting capitalization to nn.Linear\n","        self.out = nn.Linear(H2, out_features)  # Correcting capitalization to nn.Linear\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))  # Correcting indentation\n","        x = F.relu(self.fc2(x))  # Correcting indentation\n","        x = self.out(x)\n","        return x\n","\n","# Pick a manual seed for randomization\n","torch.manual_seed(21)\n","model = Model()\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n","my_df = pd.read_csv(url)\n","\n","#Changed the last column from strings to int\n","my_df['species'] = my_df['species'].replace('setosa', 0)\n","my_df['species'] = my_df['species'].replace('versicolor', 1)\n","my_df['species'] = my_df['species'].replace('virginica', 2)\n","\n","#Train, test, split! Set a,b  Variables that will store the split values\n","a = my_df.drop('species', axis=1)          #We are training our model to predict species on the basis on 4 features\n","b = my_df['species']                       # Species--> Output variable; so we have split the dataset as input/output variables\n","\n","#Convert these into numpy arrays\n","a = a.values\n","b = b.values\n","\n","from sklearn.model_selection import train_test_split\n","#Train Test Split\n","a_train, a_test, b_train, b_test = train_test_split(a,b, test_size=0.2, random_state=21)\n","#Test size 20%-->0.2, so Pytorch knows that the rest, training size, is 80%\n","\n","#Convert a features to float tensors\n","a_train = torch.FloatTensor(a_train)  # Float bcz the numbers in the array are decimals\n","a_test = torch.FloatTensor(a_test)\n","\n","#Convert b labels to float tensors long\n","b_train = torch.LongTensor(b_train)\n","b_test = torch.LongTensor(b_test)\n","# Long tensors are 64bit integers\n","\n","# Set the criterion of model to measure the error\n","# How far off the predictions are from the data\n","criterion = nn.CrossEntropyLoss()\n","import torch.optim as optim\n","# Choose Adam Optimizer\n","# lr = Learning rate (if error doesn't go down after a bunch of iterations (epochs), lower the learning rate)\n","optimizer= optim.Adam(model.parameters(),lr=0.01)        #lower the lr, the longer it takes for the model to learn\n","\n","# Set the criterion of model to measure the error\n","# How far off the predictions are from the data\n","criterion = nn.CrossEntropyLoss()\n","import torch.optim as optim\n","# Choose Adam Optimizer\n","# lr = Learning rate (if error doesn't go down after a bunch of iterations (epochs), lower the learning rate)\n","optimizer= optim.Adam(model.parameters(),lr=0.1)        #lower the lr, the longer it takes for the model to learn\n","\n","#Train our model\n","epochs = 100\n","losses = []\n","for i in range(epochs):\n","  b_pred = model.forward(a_train)\n","  loss = criterion(b_pred, b_train)\n","  losses.append(loss.detach().numpy())       # loss would be a tensor, convert as numpy\n","  if i % 10 == 0:\n","    print (f'Epoch {i} and loss: {loss}')\n","\n","  # Do backpropagation: Take the error rate of forward propagation\n","  # Feed it back through the network to fine-tune the weights\n","  optimizer.zero_grad()  # Zero the gradients before running the backward pass\n","  loss.backward()  # Backpropagation: Compute gradients of the loss with respect to model parameters\n","  optimizer.step()  # Perform a single optimization step (parameter update)\n","\n","\n","\n","#Create graph\n"," #plt.plot(range(epochs), losses)\n"," #plt.ylabel(\"loss/error\")\n"," #plt.xlabel('Epoch')\n","\n","#Evaluate Model on Test dataset (Model Validation)\n","with torch.no_grad():                     #turn off back propagation\n","  b_eval = model.forward(a_test)          #a_test are features from our test set\n","                                          # y_eval are predictions\n","  loss = criterion(b_eval, b_test)        # Find loss: prediction vs test set value\n","\n","# The diff of the above loss and loss in the training data we found above is high\n","correct = 0\n","with torch.no_grad():\n","  for i, data in enumerate(a_test):\n","    b_val = model.forward(data)  # Will tell what flower type our NN think it is\n","    print( f'{i+1}.) {str(b_val)} \\t {b_test[i]} \\t {b_val.argmax().item()}')\n","    # Prediction is correct or not\n","    if b_val.argmax().item() == b_test[i]:\n","      correct +=1\n","\n","print(f'We got {correct} correct')\n","print(f' Fuck off _|_ \\t My first Neural Network is here')\n","# In the output tensor, we are getting 3 values bcz our out has 3 nodes\n","# As there are 3 species of Iris flower. The model is evaluating which out of 3 is correct\n","# The correct species is reflected by max weigth of a node.\n","\n","\n","#Passing a new iris to see what the model predicts\n"," #new_iris = torch.tensor([1.45, 5.65, 3.54, 2.4])\n"," #with torch.no_grad():\n"," #  print (model(new_iris))\n","\n","# Save our NN Model in the trained state into a dictionary (where weights of the nodes are adjusted from the training)\n","torch.save(model.state_dict(), 'My_Iris_NN.pt')\n","\n","#Load the saved model\n","new_model = Model()\n","new_model.load_state_dict(torch.load('My_Iris_NN.pt'))\n","\n","#Evaluate the model\n","new_model.eval()"]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'Iris flower NN model')\n"],"metadata":{"id":"v8smPLKiLVuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_model = model()\n","new.model.load_state_dict(torch.load('Iris flower NN model'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"b_j7u7Y_aP09","executionInfo":{"status":"error","timestamp":1711366966133,"user_tz":0,"elapsed":417,"user":{"displayName":"Siddharth Asthana","userId":"02587652800522319733"}},"outputId":"d64df882-f510-45fe-bfbe-6a88e6285f27"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"Model.forward() missing 1 required positional argument: 'x'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-225fcbf032f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iris flower NN model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Model.forward() missing 1 required positional argument: 'x'"]}]},{"cell_type":"code","source":["new_model.eval()"],"metadata":{"id":"Ki6u6pKzatlM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711451331864,"user_tz":0,"elapsed":313,"user":{"displayName":"Siddharth Asthana","userId":"02587652800522319733"}},"outputId":"7d71af31-a3e8-45c5-b028-da2de0a4bfa4"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (fc1): Linear(in_features=4, out_features=8, bias=True)\n","  (fc2): Linear(in_features=8, out_features=9, bias=True)\n","  (out): Linear(in_features=9, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":[],"metadata":{"id":"eAQC6THRctlv"},"execution_count":null,"outputs":[]}]}